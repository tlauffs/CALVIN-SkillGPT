{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  353780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 12:41:03.727006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:41:03.748385: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:41:03.764118: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:41:03.773684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:41:03.788360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-25 12:41:03.788487: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^^^^^^^^^^^\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>can only test a child process\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "       ^^Exception ignored in: ^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>\n",
      "^Traceback (most recent call last):\n",
      "Exception ignored in: ^  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>\n",
      "    ^Traceback (most recent call last):\n",
      "^self._shutdown_workers()^Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "^\n",
      "\n",
      "^  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "    Traceback (most recent call last):\n",
      "^self._shutdown_workers()  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    ^\n",
      "    \n",
      "if w.is_alive():Exception ignored in:   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>\n",
      "Exception ignored in:            File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>assert self._parent_pid == os.getpid(), 'can only test a child process' if w.is_alive():Traceback (most recent call last):\n",
      "    \n",
      "\n",
      "\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      " if w.is_alive():Traceback (most recent call last):\n",
      "  \n",
      "      self._shutdown_workers()  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    \n",
      "          File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "   self._shutdown_workers()       \n",
      "^if w.is_alive(): ^    File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "\n",
      "  ^       if w.is_alive():^  \n",
      "^^ ^ ^^  ^^^  ^^^^ ^^^ ^^^ ^^ ^ ^^^^  ^^ ^ ^\n",
      "^^^^^  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^^^^^^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^^^\n",
      "^\n",
      "^^^   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^ ^^^^ ^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process' ^^^^\n",
      " ^^^ \n",
      "^  ^^^   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      " ^\n",
      "^      \n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'      ^\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process' ^      \n",
      " assert self._parent_pid == os.getpid(), 'can only test a child process' ^  ^\n",
      " ^  ^^      ^ ^  ^^\n",
      "   ^^ AssertionError ^ :  ^   can only test a child process^ ^ ^\n",
      " ^ ^ ^    ^^  ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^Exception ignored in: ^^^^<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>^^^^\n",
      "^^^^^Traceback (most recent call last):\n",
      "^^^  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "^^^^^^^    ^^^^^self._shutdown_workers()^^^\n",
      "^^^^^^  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "^^^^^^^^    ^^^^^if w.is_alive():^^^\n",
      "^^^\n",
      "AssertionError^:  ^^^ can only test a child process^^\n",
      "\n",
      "^ ^^^AssertionError ^^ : ^^ can only test a child process^^^ ^^^^\n",
      "^^^^\n",
      "^^^^AssertionError^\n",
      "^: ^AssertionError\n",
      "^: ^can only test a child processAssertionError^: \n",
      "can only test a child process^\n",
      "^can only test a child process\n",
      "^^^Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n",
      "\n",
      "   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "      if w.is_alive(): \n",
      "   Exception ignored in:  Exception ignored in:  <function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0><function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>\n",
      " \n",
      "Exception ignored in:   Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f8ef94f18a0>   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "       \n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      " ^Traceback (most recent call last):\n",
      "^self._shutdown_workers()       File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "^self._shutdown_workers()^    \n",
      "^^self._shutdown_workers()\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "^\n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "^          File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1461, in _shutdown_workers\n",
      "^^if w.is_alive():    ^if w.is_alive():^^\n",
      "^^if w.is_alive(): \n",
      "^\n",
      "^ ^ ^  ^  ^^ ^  ^^   ^  ^\n",
      "     ^   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^^    ^^^^assert self._parent_pid == os.getpid(), 'can only test a child process'^^^^\n",
      "^^^^^^^ ^^^^^^^^ ^^^^ ^^^^ ^^ ^^^^ ^^^^^\n",
      "^\n",
      "^^   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^^     \n",
      "  File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "^assert self._parent_pid == os.getpid(), 'can only test a child process'   File \"/home/tim/anaconda3/envs/cap-env/lib/python3.11/multiprocessing/process.py\", line 160, in is_alive\n",
      "    \n",
      " \n",
      "AssertionError    assert self._parent_pid == os.getpid(), 'can only test a child process':  assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "^ can only test a child process\n",
      "^   ^  \n",
      "^     ^  ^  ^   ^   ^   ^    ^ ^  ^^ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^^: ^^^can only test a child process^\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^AssertionError^^^: ^^\n",
      "can only test a child processAssertionError^\n",
      ": ^^can only test a child process^\n",
      "^\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observations:  torch.Size([64, 42, 2048])\n",
      "instructions:  torch.Size([64, 512])\n",
      "actions:  torch.Size([64, 42, 2])\n",
      "gpt_tokens:  torch.Size([64, 25])\n",
      "gpt_mask:  torch.Size([64, 35])\n",
      "tensor([6649,  485,  262, 2266, 9197, 3371,  262, 4220, 3641,  220,  198,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "#############################################\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pdb\n",
    "import h5py\n",
    "from transformers import GPT2Tokenizer\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class AttrDict(dict):\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        try:\n",
    "            return self.__getitem__(attr)\n",
    "        except KeyError:\n",
    "            raise AttributeError(\"Attribute %r not found\" % attr)\n",
    "\n",
    "    def __getstate__(self):\n",
    "        return self\n",
    "\n",
    "    def __setstate__(self, d):\n",
    "        self = d\n",
    "\n",
    "def collate_batch(batch):\n",
    "\n",
    "    behaviour_lengths = [item.behaviour_length for item in batch]\n",
    "\n",
    "    images = [torch.tensor(item.observations) for item in batch]\n",
    "    images = pad_sequence(images, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    actions = [torch.tensor(item.actions) for item in batch]\n",
    "    actions = pad_sequence(actions, batch_first=True, padding_value=0.0)\n",
    "\n",
    "    instructions = torch.stack([torch.tensor(item.instruction) for item in batch])\n",
    "\n",
    "    gpt_tokens = torch.stack([item.gpt_tokens for item in batch])\n",
    "    gpt_mask = torch.stack([item.gpt_mask for item in batch])\n",
    "\n",
    "    gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "    # Decode gpt tokens into text\n",
    "    text_list = []\n",
    "    stop_words = ['close', 'move', 'next', 'push', 'put', 'slide', 'the', 'to', 'towards', '!', '\\n']\n",
    "\n",
    "    # Decode gpt tokens into text\n",
    "    text_list = [gpt_tokenizer.decode(x).replace(\"!\", \"\").split() for x in gpt_tokens]\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(['close', 'move', 'next', 'push', 'put', 'slide', 'the', 'to', 'towards', '!', '\\n'])\n",
    "    text_list_clean = [[word for word in sublist if word not in stop_words] for sublist in text_list]\n",
    "\n",
    "    # print(text_list_clean)\n",
    "    # text_list_clean_array = np.array(text_list_clean)\n",
    "    text_list_clean_array = np.array(text_list_clean, dtype=object)\n",
    "\n",
    "    # print(text_list_clean_array)\n",
    "\n",
    "    #similarity_matrix = (text_list_clean_array[:, None] == text_list_clean_array).all(axis=2)\n",
    "    similarity_matrix = (text_list_clean_array[:, None] == text_list_clean_array).all()\n",
    "\n",
    "    # print(similarity_matrix)\n",
    "    \n",
    "    # false_negative_mask = similarity_matrix\n",
    "\n",
    "    # ??????????\n",
    "    false_negative_mask = similarity_matrix  - np.eye(len(text_list_clean), dtype=float)\n",
    "    false_negative_mask = np.logical_not(false_negative_mask).astype(float)\n",
    "    false_negative_mask = np.where(false_negative_mask == 0.0, -np.inf, false_negative_mask)\n",
    "    false_negative_mask = np.where(false_negative_mask == 0.0, -1e20, false_negative_mask)\n",
    "\n",
    "    return AttrDict({'observations': images, 'actions': actions, 'instruction': instructions, \n",
    "                     'gpt_tokens': gpt_tokens, 'gpt_mask': gpt_mask, 'false_negative_mask': false_negative_mask,\n",
    "                     'behaviour_lengths': behaviour_lengths})\n",
    "\n",
    "\n",
    "class BehaviourDatasetCached(Dataset):\n",
    "    def __init__(self, phase='train', data=None):\n",
    "\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "        self.all_data = data\n",
    "\n",
    "        dataset_len = len(list(self.all_data.keys()))\n",
    "        # dataset_len = 50000\n",
    "        self.dataset_indices = np.arange(dataset_len)\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(self.dataset_indices)\n",
    "\n",
    "        if phase == 'train':\n",
    "            self.dataset = self.dataset_indices[:int(0.8 * dataset_len)]\n",
    "            print(\"Dataset length: \", len(self.dataset))\n",
    "\n",
    "        elif phase == 'val':\n",
    "            self.dataset = self.dataset_indices[int(0.8 * dataset_len):]\n",
    "            print(\"Dataset length: \", len(self.dataset))\n",
    "\n",
    "        self.max_seq_len = 25\n",
    "        self.prefix_length = 10\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((180, 180)),\n",
    "            transforms.ToTensor() \n",
    "        ])\n",
    "\n",
    "    def pad_tokens(self, text_data):\n",
    "        tokens = torch.tensor(self.gpt_tokenizer.encode(text_data), dtype=torch.int64)\n",
    "        padding = self.max_seq_len - tokens.shape[0]\n",
    "        if padding > 0:\n",
    "            tokens = torch.cat((tokens, torch.zeros(padding, dtype=torch.int64) - 1))\n",
    "        elif padding < 0:\n",
    "            tokens = tokens[:self.max_seq_len]\n",
    "        mask = tokens.ge(0)  # mask is zero where we out of sequence\n",
    "        tokens[~mask] = 0\n",
    "        mask = mask.float()\n",
    "        mask = torch.cat((torch.ones(self.prefix_length), mask), dim=0)  # adding prefix mask\n",
    "        return tokens, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.dataset[idx]\n",
    "        data = self.all_data[str(index)]\n",
    "        observations = data[\"observations\"][()]\n",
    "        actions = data[\"actions\"][()]\n",
    "        instruction = data[\"clip_instruction_features\"][()].squeeze(0)\n",
    "        text_data = data[\"instruction\"][()]\n",
    "        behaviour_length = actions.shape[0]\n",
    "\n",
    "        gpt_tokens, gpt_mask = self.pad_tokens(text_data.decode())\n",
    "        \n",
    "        return AttrDict({'observations': observations, 'actions': actions, 'instruction': instruction, \n",
    "                         'gpt_tokens': gpt_tokens, 'gpt_mask': gpt_mask, 'behaviour_length': behaviour_length})\n",
    "    \n",
    "\n",
    "\n",
    "dataset = h5py.File('/media/tim/E/datasets/lang_table/lang_table_test.h5', 'r')\n",
    "train_dataset = BehaviourDatasetCached(phase='train', data=dataset)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                                batch_size=64, \n",
    "                                shuffle=True, \n",
    "                                drop_last=True,\n",
    "                                num_workers=6,\n",
    "                                prefetch_factor=5,\n",
    "                                collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    print(\"observations: \", batch.observations.shape)\n",
    "    print(\"instructions: \", batch.instruction.shape)\n",
    "    print(\"actions: \", batch.actions.shape)\n",
    "    print(\"gpt_tokens: \", batch.gpt_tokens.shape)\n",
    "    print(\"gpt_mask: \", batch.gpt_mask.shape)\n",
    "    print(batch.gpt_tokens[1])\n",
    "    print(batch.gpt_mask[1])\n",
    "    # print(\"behaviour_length: \", batch.behaviour_length)\n",
    "    print(\"#############################################\")\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
